{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e478fba8-deb1-4dfb-851f-cf82df406cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'query1.finance.yahoo.com\\', port=443): Max retries exceeded with url: /v1/test/getcrumb (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002632C006090>: Failed to resolve \\'query1.finance.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'query1.finance.yahoo.com\\', port=443): Max retries exceeded with url: /v1/test/getcrumb (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002632C098500>: Failed to resolve \\'query1.finance.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'query1.finance.yahoo.com\\', port=443): Max retries exceeded with url: /v1/test/getcrumb (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002632C098F20>: Failed to resolve \\'query1.finance.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'query1.finance.yahoo.com\\', port=443): Max retries exceeded with url: /v1/test/getcrumb (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002632C099910>: Failed to resolve \\'query1.finance.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'query1.finance.yahoo.com\\', port=443): Max retries exceeded with url: /v1/test/getcrumb (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002632C09A0F0>: Failed to resolve \\'query1.finance.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Standardize the features for anomaly detection\u001b[39;00m\n\u001b[0;32m     61\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 62\u001b[0m df_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(all_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_change\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Initialize the Isolation Forest model\u001b[39;00m\n\u001b[0;32m     65\u001b[0m model \u001b[38;5;241m=\u001b[39m IsolationForest(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, contamination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:876\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:912\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    911\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    913\u001b[0m     X,\n\u001b[0;32m    914\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    915\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    916\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    917\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    918\u001b[0m )\n\u001b[0;32m    919\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1072\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1072\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1076\u001b[0m         )\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1079\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Set up the visualization aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the list of companies to analyze (by stock symbol)\n",
    "companies = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "bright_colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0']\n",
    "\n",
    "# Function to fetch live stock data from Yahoo Finance\n",
    "def fetch_stock_data(symbol, start_date='2020-01-01'):\n",
    "    stock_data = yf.download(symbol, start=start_date)\n",
    "    stock_data.reset_index(inplace=True)\n",
    "    stock_data['Symbol'] = symbol\n",
    "    return stock_data\n",
    "\n",
    "# Function to display stock anomalies for a specific company\n",
    "def display_anomalies_for_company(company, all_data, anomalies):\n",
    "    company_data = all_data[all_data['Symbol'] == company]\n",
    "    company_anomalies = anomalies[anomalies['Symbol'] == company]\n",
    "\n",
    "    # Create new figure for the company-specific anomalies\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(company_data['Date'], company_data['Close'], label=f'{company} Close Price', color='blue')\n",
    "    plt.scatter(company_anomalies['Date'], company_anomalies['Close'], color='red', label='Anomalies', marker='x')\n",
    "    plt.title(f'{company} Stock Price with Anomalies', fontsize=16)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Closing Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch data for all companies dynamically\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for company in companies:\n",
    "    data = fetch_stock_data(company)  # This will fetch fresh, live data each time\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Sort by date for time series analysis\n",
    "all_data.sort_values('Date', inplace=True)\n",
    "\n",
    "# Feature engineering: Create new features like returns, moving averages, etc.\n",
    "all_data['returns'] = all_data['Close'].pct_change()\n",
    "all_data['volume_change'] = all_data['Volume'].pct_change()\n",
    "\n",
    "# Drop missing values that arise from feature creation\n",
    "all_data.dropna(subset=['returns', 'volume_change'], inplace=True)\n",
    "\n",
    "# Standardize the features for anomaly detection\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(all_data[['returns', 'volume_change']])\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "\n",
    "# Fit the model and predict anomalies (-1 indicates anomaly)\n",
    "all_data['anomaly'] = model.fit_predict(df_scaled)\n",
    "\n",
    "# Filter anomalies\n",
    "anomalies = all_data[all_data['anomaly'] == -1]\n",
    "\n",
    "### Part 1: Anomalies Detection - Separate Graphs for all companies\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "fig.suptitle('Anomalies in Stock Prices for Multiple Companies', fontsize=18)\n",
    "\n",
    "for i, company in enumerate(companies):\n",
    "    row, col = divmod(i, 3)  # Arrange in 2 rows, 3 columns\n",
    "    company_data = all_data[all_data['Symbol'] == company]\n",
    "    company_anomalies = anomalies[anomalies['Symbol'] == company]\n",
    "\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(company_data['Date'], company_data['Close'], label=f'{company} Close Price', color=bright_colors[i])\n",
    "    ax.scatter(company_anomalies['Date'], company_anomalies['Close'], color='red', label='Anomalies', marker='x')\n",
    "    ax.set_title(f'{company} Stock Price', fontsize=14)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "\n",
    "    # Annotate anomalies explanation\n",
    "    anomalies_count = len(company_anomalies)\n",
    "    anomaly_text = f\"{company} had {anomalies_count} unexpected price patterns.\"\n",
    "    ax.text(0.5, -0.2, anomaly_text, transform=ax.transAxes, fontsize=10, va='center', ha='center')\n",
    "\n",
    "# Remove the empty subplot (if there are 5 graphs, one slot is empty)\n",
    "if len(companies) < 6:\n",
    "    fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "### Part 2: Investment Suggestion with Forecast and Suggested Amount\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "fig.suptitle('Investment Suggestions Based on Stock Price Forecast', fontsize=18)\n",
    "\n",
    "forecast_days = 30\n",
    "portfolio_value = 10000  # Hypothetical portfolio value\n",
    "\n",
    "investment_suggestions = []\n",
    "\n",
    "for i, company in enumerate(companies):\n",
    "    row, col = divmod(i, 3)  # Arrange in 2 rows, 3 columns\n",
    "    company_data = all_data[all_data['Symbol'] == company]\n",
    "\n",
    "    # ARIMA model for forecasting\n",
    "    model_arima = ARIMA(company_data['Close'], order=(5, 1, 0))  # (p,d,q) order of the ARIMA model\n",
    "    model_fit = model_arima.fit()\n",
    "\n",
    "    # Predicting the next 30 days\n",
    "    forecast = model_fit.forecast(steps=forecast_days)\n",
    "    forecast_dates = pd.date_range(company_data['Date'].iloc[-1], periods=forecast_days, freq='D')\n",
    "\n",
    "    # Plot forecast\n",
    "    ax_forecast = axes[row, col]\n",
    "    ax_forecast.plot(company_data['Date'], company_data['Close'], label=f'{company} Historical Price', color=bright_colors[i])\n",
    "    ax_forecast.plot(forecast_dates, forecast, label=f'{company} Forecast', linestyle='--', color='orange')\n",
    "    ax_forecast.set_title(f'{company} Stock Price Forecast', fontsize=14)\n",
    "    ax_forecast.set_xlabel('Date')\n",
    "    ax_forecast.set_ylabel('Closing Price')\n",
    "\n",
    "    # Simple Investment Strategy\n",
    "    last_closing_price = company_data['Close'].iloc[-1]\n",
    "    future_price = forecast.iloc[-1]\n",
    "\n",
    "    if future_price > last_closing_price:  # Predicted price increase\n",
    "        percentage_increase = ((future_price / last_closing_price) - 1) * 100\n",
    "        investment_advice = f\"Buy: The stock is expected to increase by {percentage_increase:.2f}%.\"\n",
    "        suggested_investment = portfolio_value * (percentage_increase / 100)  # Dynamic investment based on forecasted gain\n",
    "        advice_text = f\"Suggestion: {investment_advice}\\nInvest: ${suggested_investment:.2f}\"\n",
    "    else:  # Predicted price decrease\n",
    "        percentage_decrease = ((last_closing_price / future_price) - 1) * 100\n",
    "        investment_advice = f\"Sell: The stock is expected to decrease by {percentage_decrease:.2f}%.\"\n",
    "        suggested_sell = portfolio_value * (percentage_decrease / 100)\n",
    "        advice_text = f\"Suggestion: {investment_advice}\\nSell: ${suggested_sell:.2f}\"\n",
    "\n",
    "    investment_suggestions.append(f\"{company}: {investment_advice}\")\n",
    "\n",
    "    # Annotate investment suggestion explanation\n",
    "    ax_forecast.text(0.5, -0.2, advice_text, transform=ax_forecast.transAxes, fontsize=10, va='center', ha='center')\n",
    "\n",
    "# Remove the empty subplot (if there are 5 graphs, one slot is empty)\n",
    "if len(companies) < 6:\n",
    "    fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Print all investment suggestions\n",
    "print(\"\\n--- Investment Suggestions ---\")\n",
    "for suggestion in investment_suggestions:\n",
    "    print(suggestion)\n",
    "\n",
    "### Part 3: Asking User Which Company to Focus on for Detailed Analysis\n",
    "\n",
    "# Create dropdown for company selection in Jupyter\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=companies,\n",
    "    description='Company:',\n",
    ")\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        selected_company = change['new']\n",
    "        display_anomalies_for_company(selected_company, all_data, anomalies)\n",
    "\n",
    "# Observe the dropdown selection\n",
    "dropdown.observe(on_change)\n",
    "\n",
    "# Display dropdown\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3edb6-4e2a-4199-b9d1-9933967d7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
